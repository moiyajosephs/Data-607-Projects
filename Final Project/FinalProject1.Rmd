---
title: "Final Project: Recommendation Systems"
author: "Moiya Josephs"
date: "5/12/2022"
output: 
  html_document:
    number_sections: true
    toc: true
    toc_float: true
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(recommenderlab)
library(tidyverse)
library(reshape2)
```

# Overview

For the final project I took three data sets, all taken from Kaggle and used `recommenderlab` library on the data sets. Each data set allowed me to test the different recommendation methods and calculating the accuracy for each one/

The first data set is:

- Beauty Ratings from Amazon
- Netflix Ratings
- Book Ratings



# Beauty Recommendation

For this part of my project I used the Amazon Beauty Rating data set from Kaggle. The data set has over 2 Million customer reviews and ratings of Beauty related products sold on their website. It isa subset of all their product reviews that span from May 1996 - July 2014.

The Schema

- UserId (Customer Identification)  
- the product ASIN (Amazon's unique product identification code for each product)  
- Ratings (1-5 based on customer satisfaction)   
- Timestamp (in UNIX time)  


## Reading the Data

```{r}
ratings <- read.csv("https://raw.githubusercontent.com/moiyajosephs/Data-607-Projects/main/Final%20Project/ratings_Beauty.csv", header = TRUE, sep = ",", dec = ".", quote="")

```

```{r}
head(ratings)
```


```{r}
summary(ratings)
```



## Formatting the data


To make the dataframe into something a `recommenderlab` function can use, I had to go through a number of steps first.

### Converting to factors
First, I checked the class for each column since sparce matrix and real matrix are very particular.

```{r}
class(ratings$UserId); class(ratings$ProductId); class(ratings$Rating); class(ratings$Timestamp)
```

Changed the character columns to factors.

```{r}
ratings$UserId<- as.factor(ratings$UserId); 
ratings$ProductId <- as.factor(ratings$ProductId)
```

### Build a Sparce matrix

Convert into ratings matrix. This is done first by using the sparse matrix function. The rows will be the integer values of the `UserId` and the columns will be the `ProductId`. The x, values will be the ratings. 

```{r}
ratingsMatrix <- sparseMatrix(as.integer(ratings$UserId), as.integer(ratings$ProductId), x = ratings$Rating)
```

Next use the `colnames` and `rownames` function on the matrix so that each cell is properly labelled.
```{r}
colnames(ratingsMatrix) <- levels(ratings$ProductId)
rownames(ratingsMatrix) <- levels(ratings$UserId)
```

### Make a realRatingMatrix

Save the sparse matrix as a `realRatingMatrix`
```{r}
beauty <- as(ratingsMatrix, "realRatingMatrix") #change to beauty
```


## Working with the realRatingMatrix

With the `getRatingMatrix()` function we can see the resulting matrix from the steps above.

```{r}
getRatingMatrix(beauty)[1:10,1:4]
```

The `getRatings()` function allows us to see the just the ratings. It is also a good way to check if the realRatingMatrix identified the right numbers as ratings.


Representing visually

```{r}
data.frame(ratings = getRatings(beauty)) %>%
  ggplot(aes(ratings)) + geom_bar(width = 0.75)
```
The graph above shows that 5 star ratings are the most frequently chosen rating for the products.


## Readying the data for recommender models

The rowcounts/colcounts function allows us to view the unique number of unique row/ col values . This is important with a ratingmatrix and for recommendation system because there are some users/products with only one rating. This is not enough data to make predictions on.


```{r}
table(rowCounts(beauty))
```

```{r}
table(colCounts(beauty))
```

Limit the matrix to only include values with more than 30 column count and 10 row counts. 
```{r}
beauty <- beauty[,colCounts(beauty) >30]
```

```{r}
beauty <- beauty[rowCounts(beauty) > 10, ]
```


```{r}
getRatingMatrix(beauty)[1:10,1:4]
```
```{r}
data.frame(ratings = getRatings(beauty)) %>%
  ggplot(aes(ratings)) + geom_bar(width = 0.75)
```

As we can see the amount of ratings has decreased but ratings = 5 are still the most popular.
Now the data is ready for recommendation model

## Build the model

To use  a machine learning model we need to divide the data into training, known and unknown data. We will build the model on training data, and predict on the known data. Next we can calculate accuracy with the unknown data.


Below I decided on dividing the data so that 75% of the data is training data. I also need to note the minimum amount of rowcounts, the number of occurrences of users, available. This is important for later.
```{r}
train_proportion <- .75
min(rowCounts(beauty))
```
Below the `given` value is what we found as the minimum rowcounts. In the `evaluationscheme`, , the given parameter cannot be greater than the minimum rowcounts. 
The `goodrating` value gives the model the rating we should be considering as good. Since the data ratings ranges from 1-5 , I indicate that a good rating is anything that is 4 or above. 


```{r}
give <- 11
# What's a good rating for a binary split?
goodrating <- 4
```

```{r}
# Building a Recommender System with R by Gorakala and Usuelli. Ch.4 pp 77 - 83
set.seed(12345)
beauty_evaluation <- beauty %>% evaluationScheme(method = 'split', # single train/test split
                   train = train_proportion, # proportion of rows to train.
                   given = give, # shouldn't keep n rec. items > min(rowCounts(movie_r))
                   goodRating = goodrating, # for binary classifier analysis.
                   k = 1)
```

`Modelparams` builds the parameters for the recommended function. The method in the parameters can be cosine, ,. nn indicates to find the n most similar users. And we can also sample our data or normalized.I normalized thed data since user rating can be biased, normalizing th data will help make it fair. The example I used to make the modelparams is from the tutorial []().

```{r}
# Building a Recommender System with R by Gorakala and Usuelli. Ch.4 pp 84
model_params <- list(method = "cosine",
                     nn = 10, # find each user's 10 most similar users.
                     sample = FALSE, # already did this.
                     normalize = "center")
```



## Divide the data

```{r}
set.seed(88)
train <- getData(beauty_evaluation, "train")
known <- getData(beauty_evaluation, "known")
unknown <- getData(beauty_evaluation, "unknown")
```

### Popular

The popular method in recommender lab allows you to make recommendations based on the other popularly rated items. It is a popular recommendation method implementation. First we train on the training data, predict on the known and calculate accuracy on the unknown.

```{r}
model_method <- "POPULAR"
# Training

modelPOP <- Recommender(train, method = model_method)
```



```{r}

predPOP <- predict(modelPOP, newdata = known, type = "ratings")


# Accuracy
accPOP <- calcPredictionAccuracy(predPOP, unknown)
```



```{r}
accPOP
```

Get the top beatuy products



```{r}
getModel(modelPOP)
```

```{r}
getModel(modelPOP)$topN
```

The result contains two ordered top-N recommendation lists, one for each user. 
The recommended items can be inspected as a list.
```{r}
recom <- predict(modelPOP, known, n=3)
head(as(recom,"list"))
```

```{r}
recom3 <- bestN(recom, n = 3)
head(as(recom3, "list"))

```




### Random 

```{r}
model_method <- "RANDOM"
# Training

modelRND <- Recommender(train, method = model_method)
```


```{r}

predRND <- predict(modelRND, newdata = known, type = "ratings")


# Accuracy
accRND <- calcPredictionAccuracy(predRND, unknown)
```



```{r}
accRND

```


## Conclusions

In conclusion the popular method was able to predict with a better accuracy than the random method.


----------------

# Netflix

Netflix data was a little more difficult to get in the format needed to make the recommendation engine. Each movie was listed in the below format on 4 different files. 
Movie:
customerID, Rating, Time
There were # movies across multiple files.

To get each individual movie I made a python script that will read the text file and at each :, this will indicate a new movies ratings. With each new movie it will become its own file. With future iterations of this project I would like to use all the files, but for this project I will test the first 10 movies. This limits the scale and accuracy of the recommendation engine since the training data is a much smaller subset of the larger one. 

## Reading in each movie


Fist I read the text files individually. Next I remove the timestamp column and add in the movie id as a column, so we know which rating belongs to which movie. 

```{r}
movie1<- read.delim("https://raw.githubusercontent.com/moiyajosephs/Data-607-Projects/main/Final%20Project/movie-data/2.txt", header = FALSE, sep = ",", dec = ".")
# add movie id
movie1<- movie1[,c(1,2)]
movie_id <- rep(c(1),547)
movie1<- cbind(movie_id,movie1)
```

```{r}
movie_id <- rep(c(2),145)
movie2<- read.delim("https://raw.githubusercontent.com/moiyajosephs/Data-607-Projects/main/Final%20Project/movie-data/3.txt", header = FALSE, sep = ",", dec = ".")
movie2<- movie2[,1:2]
movie2<- cbind(movie_id,movie2)
```


```{r}
movie_id <- rep(c(3),2012)
movie3<- read.delim("https://raw.githubusercontent.com/moiyajosephs/Data-607-Projects/main/Final%20Project/movie-data/4.txt", header = FALSE, sep = ",", dec = ".")
movie3<- movie3[,1:2]
movie3<- cbind(movie_id,movie3)
```

Using rbind, I can combine all the movies into one. 

```{r}
movies<- rbind(movie1, movie2, movie3)

```

```{r}
dim(movies)

```

`Dcast` Allows us to pivot the user id to the rows and the movie id to the columns, making it into a matrix like structure. 

```{r}
ratingsMatrix <- dcast(movies, V1~movie_id, value.var = "V2" )

```


Again we subtract the user id from actual data, since it will confuse `recommenderlab` functions and be counted as a rating.


```{r}
ratingsMatrix <- as.matrix(ratingsMatrix[-c(1)])
```
  
## Real Rating Matrix

Now we can coerce the matrix into a `realRatingMatrix`.
  
```{r}
# Convert rating matrix into a recommenderlab sparse matrix
ratingsMatrix <- as(ratingsMatrix, "realRatingMatrix")

ratingsMatrix
```
Now to display the ratings matrix.
```{r}
getRatingMatrix(ratingsMatrix)[1:10,1:3]
```   


A more condensed look of the ratings.
```{r}
vec_ratings <- as.vector(ratingsMatrix@data)

# Unique ratings
unique(vec_ratings)
```

```{r}
data.frame(ratings = getRatings(ratingsMatrix)) %>%
  ggplot(aes(ratings)) + geom_bar(width = 0.75)
```



```{r}
( ratingsMatrix <- ratingsMatrix[ , colCounts(ratingsMatrix) != 0] )

```

```{r}
table(rowCounts(ratingsMatrix))
```

```{r}
min(rowCounts(ratingsMatrix))
```


## Divide up the data 


```{r}
net_evaluation <- ratingsMatrix %>% evaluationScheme(method = "split", train = 0.80, given = 1)

net_evaluation
```

```{r}
model_params <- list(method="cosine", 
                    nn = 5,
                    sample = FALSE,
                    normalize = "center")

```


```{r}
train <- getData(net_evaluation, "train")
train
```

```{r}
test_known <- getData(net_evaluation, "known")
test_known
```

```{r}
test_unknown <- getData(net_evaluation, "unknown")
test_unknown
```


### Popular


```{r}
model_method <- "POPULAR"
# Training

modelPOP <- Recommender(train, method = model_method)
```


```{r}

predPOP <- predict(modelPOP, test_known, type = "ratings")


# Accuracy
accPOP <- calcPredictionAccuracy(predPOP, test_unknown)
```

```{r}
accPOP
```

With sparse matrixes NaN can occur if there is not enough data. 

### Get the top N

With popular recommendation model we can also distinguish the top n items from the data set.

```{r}
getModel(modelPOP)
```

```{r}
getModel(modelPOP)$topN
```

The result contains two ordered top-N recommendation lists, one for each user. 
The recommended items can be inspected as a list. 
```{r}
recom <- predict(modelPOP, test_known, n=3)
head(as(recom,"list"))
```

```{r}
recom3 <- bestN(recom, n = 3)
head(as(recom3, "list"))

```





### Random

```{r}
model_method <- "RANDOM"
# Training

modelRND <- Recommender(train, method = model_method)
```


```{r}

predRND <- predict(modelRND, test_known, type = "ratings")


# Accuracy
accRND <- calcPredictionAccuracy(predRND, test_unknown)
```

```{r}
accRND
```

### LIBMF



```{r}
model_method <- "LIBMF"
# Training

modelLIBMF <- Recommender(train, method = model_method)
```


```{r}

predLIBMF <- predict(modelLIBMF, test_known, type = "ratings")


# Accuracy
accLIBMF <- calcPredictionAccuracy(predLIBMF, test_unknown)
```

```{r}
accLIBMF
```


## conclusion


LIBMF and popular was more accurate than the RANDOM method. 


-------

# Book ratings


```{r}
bookratings <- read.csv("https://raw.githubusercontent.com/moiyajosephs/Data-607-Projects/main/Final%20Project/Ratings.csv", header = TRUE, sep = ",", dec = ".")

```
Check the class for each column since pare matrix and rea matrix are very partovulat

```{r}
head(bookratings)
```


```{r}
class(bookratings$User.ID); class(bookratings$ISBN); class(bookratings$Book.Rating);
```
The dataset is very large so i will take only 10000 ratings.

```{r}
booksratings <- sample_n(bookratings, 10000)
```


had to change this  to factors
```{r}
bookratings$ISBN <- as.factor(bookratings$ISBN)
```

Convert into ratings matrix

```{r}
ratingsMatrix <- sparseMatrix(as.integer(bookratings$User.ID), as.integer(bookratings$ISBN), x = bookratings$Book.Rating)
colnames(ratingsMatrix) <- levels(bookratings$ISBN)
rownames(ratingsMatrix) <- levels(bookratings$User.ID)
books <- as(ratingsMatrix, "realRatingMatrix")
```

```{r}
getRatingMatrix(books)[1:10,1:4]
```

```{r}
data.frame(ratings = getRatings(books)) %>%
  ggplot(aes(ratings)) + geom_bar(width = 0.75)
```


```{r}
(rowCounts(books))
```

```{r}
table(colCounts(books))[1:100]
```

```{r}
( books <- books[ , colCounts(books) != 0] )
```



```{r}
books_subset <- books[ , colCounts(books) > 30]
books_subset <- books_subset[rowCounts(books_subset) > 10, ]
books_subset
```


```{r}

getRatingMatrix(books_subset)[1:10,1:4]
```

```{r}
getRatings(books_subset)
```
```{r}
data.frame(ratings = getRatings(books_subset)) %>%
  ggplot(aes(ratings)) + geom_bar(width = 0.75)
```


## Divide the data 
Good rating is 5, the ratings go all the way up to 10

```{r}
set.seed(88)
eval <- evaluationScheme(books_subset, method = "split", train = 0.8, given = 5, goodRating = 5)
train <- getData(eval, "train")
known <- getData(eval, "known")
unknown <- getData(eval, "unknown")
```

### Popular

```{r}
model_method <- "POPULAR"
# Training

modelPOP <- Recommender(train, method = model_method)
```


```{r}

predPOP <- predict(modelPOP, newdata = known, type = "ratings")


# Accuracy
accPOP <- calcPredictionAccuracy(predPOP, unknown)
```



```{r}
accPOP
```
The accuracy o the popular method did not perform as well on this dataset. Something with a user-based or item based may be better fit.


### Finding the top book:


```{r}
getModel(modelPOP)
```

```{r}
getModel(modelPOP)$topN
```

The result contains two ordered top-N recommendation lists, one for each user. 
The recommended items can be inspected as a list.
```{r}
recom <- predict(modelPOP, known, n=3)
head(as(recom,"list"))
```

```{r}
recom3 <- bestN(recom, n = 3)
head(as(recom3, "list"))

```





### USBF

```{r}
model_method <- "UBCF"
# Training


model_params <- list(method = "cosine",
                     nn = 10, # find each user's 10 most similar users.
                     sample = FALSE, # already did this.
                     normalize = "center")

modelUBCF <-  getData(eval, "train") %>% Recommender( method = model_method, parameter= model_params)
```


```{r}

predUBCF <- predict(modelUBCF, newdata = known, type = "ratings")

```

Using USBF this method takes the longest time to run.


### Accuracy
```{r}
accUBCF <- calcPredictionAccuracy(predUBCF, unknown)
```

```{r}
accUBCF
```
As shown above UBCF isn't accurate in predicting future items. Possibly with more work it will work.


## Conclusions
This was interesting to use to see which items would be the topN. Future iterations of the project could search for the item by the idea. This could be something useful for a business. 



# Conclusions


Popular methods seems to be the better choice based on this small look into recommender lab. However it is important to take into account which data set you are using. Something like User Based will work well with a lot of sampled users. Item based will work well with a lot of sampled 

In conclusion, I was able to learn a lot about `recommenderlab` and what it would take to build a recommendation engine. Ways to improve in the future is to possible use a technology like Spark which can handle larger amounts of data. That way I could make some more accurate predictions on the dataset. Another possible improvement would be to use another recommendation algorithm library and see if it could potentially do a better job.





# References


[Book Ratings](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset?select=Ratings.csv)

[Beauty Ratings](https://www.kaggle.com/datasets/skillsmuggler/amazon-ratings)

[Netflix Movie Ratings](https://www.kaggle.com/code/laowingkin/netflix-movie-recommendation/data)

[How to Build a Recommendation Engine in R](https://www.data-mania.com/blog/how-to-build-a-recommendation-engine-in-r/)

[Recommender System Tutorial](https://github.com/BrandonHoeft/Recommender-System-R-Tutorial/blob/master/RecommenderLab_Tutorial.md)


[Recommender Lab Documentation](https://cran.r-project.org/web/packages/recommenderlab/vignettes/recommenderlab.pdf)
